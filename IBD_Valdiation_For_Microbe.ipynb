{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Import necessary libraries"
      ],
      "metadata": {
        "id": "_H6W9nPiziog"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xUfAXTJAq8ET"
      },
      "outputs": [],
      "source": [
        "! pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import xgboost\n",
        "\n",
        "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
        "print(f\"XGBoost version: {xgboost.__version__}\")\n"
      ],
      "metadata": {
        "id": "zBXB5bVUyb1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall scikit-learn -y\n",
        "!pip install scikit-learn==1.5.2"
      ],
      "metadata": {
        "id": "1SeaxMgCyfGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TD-V3kRPTdU1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import os,os.path\n",
        "import re\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "import optuna\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.utils import resample\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.stats import bootstrap"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load the datasets"
      ],
      "metadata": {
        "id": "Om5Tl0oGetyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gene = pd.read_excel('IBD microbes.xlsx')\n",
        "gene"
      ],
      "metadata": {
        "id": "Nvc7xXMd5wew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gene_ibd = pd.read_excel('IBD microbe validation-iHMP final.xlsx')\n",
        "gene_ibd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "GNTDp0HU5r28",
        "outputId": "b66d0ed1-c5ed-45de-f9ca-8952f71c6327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Group  Limivivens  UBA11774  Ventricola  JAGTTR01  Choladousia  \\\n",
              "0        IBD    0.000291  0.000013    0.000008  0.000005     0.000066   \n",
              "1        IBD    0.000089  0.000060    0.000109  0.000094     0.000069   \n",
              "2        IBD    0.000021  0.000114    0.000030  0.000019     0.000214   \n",
              "3        IBD    0.000012  0.000251    0.000084  0.000013     0.000035   \n",
              "4    Healthy    0.000115  0.000353    0.000040  0.000218     0.000199   \n",
              "..       ...         ...       ...         ...       ...          ...   \n",
              "377      IBD    0.000407  0.000028    0.000829  0.000686     0.000242   \n",
              "378      IBD    0.000873  0.002969    0.000466  0.000833     0.000659   \n",
              "379      IBD    0.000142  0.000034    0.000025  0.000154     0.000168   \n",
              "380      IBD    0.000035  0.000209    0.000009  0.000004     0.000020   \n",
              "381  Healthy    0.000280  0.000163    0.000214  0.000389     0.000297   \n",
              "\n",
              "     Butyribacter      UMGS1601  RGIG4708  Copromorpha    SIG607  \\\n",
              "0        0.000093  0.000000e+00  0.000000     0.000112  0.000000   \n",
              "1        0.002579  2.851185e-06  0.000000     0.000013  0.000000   \n",
              "2        0.000135  1.766807e-06  0.000000     0.000014  0.000002   \n",
              "3        0.000026  1.001865e-06  0.000002     0.000021  0.000000   \n",
              "4        0.001342  3.430991e-06  0.000002     0.000046  0.000002   \n",
              "..            ...           ...       ...          ...       ...   \n",
              "377      0.006064  9.453251e-06  0.000004     0.000158  0.000007   \n",
              "378      0.003964  1.246941e-05  0.000011     0.000188  0.000000   \n",
              "379      0.000542  1.905200e-06  0.000000     0.000027  0.000000   \n",
              "380      0.000025  8.838820e-07  0.000004     0.000004  0.000000   \n",
              "381      0.000236  8.209025e-06  0.000053     0.000075  0.000000   \n",
              "\n",
              "     Faecalibaculum  Actinomarina    CAG-83  Bariatricus    UMGS1601.1  \n",
              "0      2.693869e-06      0.000000  0.000190     0.000016  0.000000e+00  \n",
              "1      0.000000e+00      0.000000  0.000286     0.000079  2.851185e-06  \n",
              "2      4.038417e-06      0.000001  0.000351     0.000124  1.766807e-06  \n",
              "3      0.000000e+00      0.000000  0.006983     0.000240  1.001865e-06  \n",
              "4      1.547310e-06      0.000000  0.005275     0.000825  3.430991e-06  \n",
              "..              ...           ...       ...          ...           ...  \n",
              "377    7.171432e-07      0.000000  0.008527     0.001889  9.453251e-06  \n",
              "378    1.960599e-06      0.000001  0.008567     0.003799  1.246941e-05  \n",
              "379    6.562356e-06      0.000000  0.000231     0.000495  1.905200e-06  \n",
              "380    6.734339e-07      0.000000  0.000143     0.000020  8.838820e-07  \n",
              "381    9.850830e-07      0.000000  0.001663     0.000905  8.209025e-06  \n",
              "\n",
              "[382 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-edf7f30e-740e-4981-833a-14d4099c2eb4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Group</th>\n",
              "      <th>Limivivens</th>\n",
              "      <th>UBA11774</th>\n",
              "      <th>Ventricola</th>\n",
              "      <th>JAGTTR01</th>\n",
              "      <th>Choladousia</th>\n",
              "      <th>Butyribacter</th>\n",
              "      <th>UMGS1601</th>\n",
              "      <th>RGIG4708</th>\n",
              "      <th>Copromorpha</th>\n",
              "      <th>SIG607</th>\n",
              "      <th>Faecalibaculum</th>\n",
              "      <th>Actinomarina</th>\n",
              "      <th>CAG-83</th>\n",
              "      <th>Bariatricus</th>\n",
              "      <th>UMGS1601.1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IBD</td>\n",
              "      <td>0.000291</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000112</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.693869e-06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000190</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IBD</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.002579</td>\n",
              "      <td>2.851185e-06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000286</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>2.851185e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IBD</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000114</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000135</td>\n",
              "      <td>1.766807e-06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>4.038417e-06</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000351</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>1.766807e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IBD</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000251</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>1.001865e-06</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006983</td>\n",
              "      <td>0.000240</td>\n",
              "      <td>1.001865e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Healthy</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>0.000353</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.000218</td>\n",
              "      <td>0.000199</td>\n",
              "      <td>0.001342</td>\n",
              "      <td>3.430991e-06</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>1.547310e-06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005275</td>\n",
              "      <td>0.000825</td>\n",
              "      <td>3.430991e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>IBD</td>\n",
              "      <td>0.000407</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000829</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.006064</td>\n",
              "      <td>9.453251e-06</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>7.171432e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008527</td>\n",
              "      <td>0.001889</td>\n",
              "      <td>9.453251e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>IBD</td>\n",
              "      <td>0.000873</td>\n",
              "      <td>0.002969</td>\n",
              "      <td>0.000466</td>\n",
              "      <td>0.000833</td>\n",
              "      <td>0.000659</td>\n",
              "      <td>0.003964</td>\n",
              "      <td>1.246941e-05</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000188</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.960599e-06</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.008567</td>\n",
              "      <td>0.003799</td>\n",
              "      <td>1.246941e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>IBD</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.000168</td>\n",
              "      <td>0.000542</td>\n",
              "      <td>1.905200e-06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.562356e-06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.000495</td>\n",
              "      <td>1.905200e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>IBD</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.000209</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>8.838820e-07</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.734339e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>8.838820e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>Healthy</td>\n",
              "      <td>0.000280</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>0.000297</td>\n",
              "      <td>0.000236</td>\n",
              "      <td>8.209025e-06</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.850830e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001663</td>\n",
              "      <td>0.000905</td>\n",
              "      <td>8.209025e-06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>382 rows × 16 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edf7f30e-740e-4981-833a-14d4099c2eb4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-edf7f30e-740e-4981-833a-14d4099c2eb4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-edf7f30e-740e-4981-833a-14d4099c2eb4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b20d8db7-f6cc-46de-b0b8-9047b67cc9ae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b20d8db7-f6cc-46de-b0b8-9047b67cc9ae')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b20d8db7-f6cc-46de-b0b8-9047b67cc9ae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_dc404c7e-9fa7-4697-ab01-3dc266778262\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('gene_ibd')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_dc404c7e-9fa7-4697-ab01-3dc266778262 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('gene_ibd');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "gene_ibd",
              "summary": "{\n  \"name\": \"gene_ibd\",\n  \"rows\": 382,\n  \"fields\": [\n    {\n      \"column\": \"Group\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Healthy\",\n          \"IBD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Limivivens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00040329322385419835,\n        \"min\": 0.0,\n        \"max\": 0.00636089317314918,\n        \"num_unique_values\": 374,\n        \"samples\": [\n          0.0002916204116442945,\n          2.3441445784506773e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UBA11774\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.001450645455007418,\n        \"min\": 0.0,\n        \"max\": 0.0234741708749011,\n        \"num_unique_values\": 375,\n        \"samples\": [\n          5.441099959057865e-05,\n          4.277330000035225e-06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ventricola\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0013971728599867293,\n        \"min\": 0.0,\n        \"max\": 0.0221691803189614,\n        \"num_unique_values\": 370,\n        \"samples\": [\n          1.9457623261627265e-05,\n          3.0570329117898814e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"JAGTTR01\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00022424934115819974,\n        \"min\": 0.0,\n        \"max\": 0.0022973407659459,\n        \"num_unique_values\": 366,\n        \"samples\": [\n          1.0539427373430345e-05,\n          5.338275578475335e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choladousia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0002277396606855737,\n        \"min\": 0.0,\n        \"max\": 0.0014674328982225,\n        \"num_unique_values\": 375,\n        \"samples\": [\n          0.0001750690363700041,\n          5.4305317157309966e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Butyribacter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005642488978771887,\n        \"min\": 0.0,\n        \"max\": 0.0579168791886636,\n        \"num_unique_values\": 378,\n        \"samples\": [\n          4.76553203566406e-05,\n          5.603556790892549e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UMGS1601\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.749248856584503e-05,\n        \"min\": 0.0,\n        \"max\": 0.0003297656003759656,\n        \"num_unique_values\": 298,\n        \"samples\": [\n          1.5606536590240932e-05,\n          6.936818695125488e-06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RGIG4708\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0962330259961581e-05,\n        \"min\": 0.0,\n        \"max\": 0.00011317322567669,\n        \"num_unique_values\": 182,\n        \"samples\": [\n          2.346463384722104e-06,\n          3.627541016908573e-06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Copromorpha\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00014130126731416785,\n        \"min\": 0.0,\n        \"max\": 0.00129120362022041,\n        \"num_unique_values\": 366,\n        \"samples\": [\n          4.3856005847733845e-05,\n          6.62566803927025e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SIG607\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.872276208229908e-06,\n        \"min\": 0.0,\n        \"max\": 1.098772103861067e-05,\n        \"num_unique_values\": 137,\n        \"samples\": [\n          1.044272115234334e-06,\n          1.0391486075339382e-06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Faecalibaculum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.484184234598775e-06,\n        \"min\": 0.0,\n        \"max\": 4.3375670485551e-05,\n        \"num_unique_values\": 209,\n        \"samples\": [\n          1.3194500447768568e-06,\n          8.59611198890418e-06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actinomarina\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0633318295210904e-06,\n        \"min\": 0.0,\n        \"max\": 1.6014959585270154e-05,\n        \"num_unique_values\": 71,\n        \"samples\": [\n          9.624469691719986e-07,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CAG-83\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005923832351820055,\n        \"min\": 8.723467163475272e-06,\n        \"max\": 0.0476263159404437,\n        \"num_unique_values\": 382,\n        \"samples\": [\n          0.00100842421448016,\n          0.002828423730341\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bariatricus\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.001353451299309525,\n        \"min\": 0.0,\n        \"max\": 0.0101750967209422,\n        \"num_unique_values\": 379,\n        \"samples\": [\n          0.000470340586286208,\n          0.0005050788746898844\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UMGS1601.1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.749248856584503e-05,\n        \"min\": 0.0,\n        \"max\": 0.0003297656003759656,\n        \"num_unique_values\": 298,\n        \"samples\": [\n          1.5606536590240932e-05,\n          6.936818695125488e-06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_column = gene['Group']\n",
        "data_to_scale = gene.drop(columns=['Group'])\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data_to_scale)\n",
        "\n",
        "# Convert the scaled data back into a DataFrame and reattach the 'Group' column\n",
        "gene = pd.DataFrame(data_scaled, columns=data_to_scale.columns)\n",
        "gene['Group'] = sample_column\n",
        "\n",
        "# Rearrange the 'Group' column as the first column\n",
        "gene = gene[['Group'] + [col for col in gene.columns if col != 'Group']]\n",
        "\n",
        "print(\"Data after Min-Max scaling:\")\n",
        "print(gene)"
      ],
      "metadata": {
        "id": "fXY9kjJ6FpRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_column = gene_ibd['Group']\n",
        "data_to_scale = gene_ibd.drop(columns=['Group'])\n",
        "\n",
        "# Apply Min-Max scaling to the data (excluding the 'Group' column)\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data_to_scale)\n",
        "\n",
        "# Convert the scaled data back into a DataFrame\n",
        "gene_ibd = pd.DataFrame(data_scaled, columns=data_to_scale.columns)\n",
        "gene_ibd['Group'] = sample_column\n",
        "\n",
        "# Rearrange the 'Group' column as the first column\n",
        "gene_ibd = gene_ibd[['Group'] + [col for col in gene_ibd.columns if col != 'Group']]\n",
        "\n",
        "print(\"Data after Min-Max scaling:\")\n",
        "print(gene_ibd)"
      ],
      "metadata": {
        "id": "uP8vc5DZ6FBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#XGBOOST"
      ],
      "metadata": {
        "id": "_gN-bO9T5tHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = gene.drop(['Group'], axis=1)\n",
        "y = gene['Group']\n",
        "\n",
        "# Encode categorical target labels into numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize XGBoost classifier\n",
        "model = xgb.XGBClassifier(eval_metric='logloss', random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the original test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Test Precision: {precision:.4f}')\n",
        "print(f'Test F1 Score: {f1:.4f}')\n",
        "print(f'Test Recall: {recall:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0Rz1UA0Yxi_",
        "outputId": "4be7db9e-3b7c-4b78-8dab-3c5e25b2195c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8727\n",
            "Test Precision: 0.8703\n",
            "Test F1 Score: 0.8711\n",
            "Test Recall: 0.8727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random Search"
      ],
      "metadata": {
        "id": "AMMNXpnpUPP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Define the parameter grid for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': np.arange(50, 200, 10),\n",
        "    'max_depth': np.arange(3, 10),\n",
        "    'learning_rate': np.linspace(0.01, 0.3, 10),\n",
        "    'subsample': np.linspace(0.5, 1.0, 10),\n",
        "    'colsample_bytree': np.linspace(0.5, 1.0, 10),\n",
        "    'gamma': np.linspace(0, 0.5, 5),\n",
        "    'min_child_weight': np.arange(1, 6)\n",
        "}\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "\n",
        "# Set up RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb, param_distributions=param_dist, n_iter=100,\n",
        "    scoring='roc_auc', cv=5, verbose=1, random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the RandomizedSearchCV model on the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters from the random search\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "# Predict on the original test set\n",
        "y_pred = random_search.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print metrics\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBLm1dEwZ1un",
        "outputId": "c6108b9a-e2be-42ac-afd9-9cb8736e8fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "Best Parameters: {'subsample': 0.7777777777777778, 'n_estimators': 160, 'min_child_weight': 1, 'max_depth': 8, 'learning_rate': 0.07444444444444444, 'gamma': 0.125, 'colsample_bytree': 0.5555555555555556}\n",
            "Accuracy: 0.87\n",
            "Precision: 0.87\n",
            "Recall: 0.87\n",
            "F1 Score: 0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bayesian Optimization"
      ],
      "metadata": {
        "id": "P3XyDsJZU0Ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'booster': trial.suggest_categorical('booster', ['gbtree', 'dart']),\n",
        "        'objective': 'binary:logistic',\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 0.5),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'min_child_weight': trial.suggest_float('min_child_weight', 0.5, 5),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300)\n",
        "    }\n",
        "\n",
        "    # Initialize the XGBoost model with the suggested hyperparameters\n",
        "    model = xgb.XGBClassifier(**params)\n",
        "\n",
        "    # Evaluate using cross-validation\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
        "\n",
        "    # Return the mean accuracy from cross-validation\n",
        "    return cv_scores.mean()\n",
        "\n",
        "# Create a study to maximize accuracy\n",
        "study = optuna.create_study(direction='maximize')\n",
        "\n",
        "# Enqueue the parameters obtained from previous RandomizedSearchCV results\n",
        "study.enqueue_trial({\n",
        "    'booster': 'gbtree',\n",
        "    'objective': 'binary:logistic',\n",
        "    'learning_rate': 0.07444444444444444,\n",
        "    'gamma':0.125,\n",
        "    'max_depth': 8,\n",
        "    'min_child_weight': 1,\n",
        "    'subsample':0.7777777777777778,\n",
        "    'colsample_bytree': 0.5555555555555556,\n",
        "    'n_estimators': 160\n",
        "})\n",
        "\n",
        "# Optimize the study using 50 trials\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Print the best parameters and cross-validation accuracy\n",
        "print(f\"Best Parameters: {study.best_params}\")\n",
        "print(f\"Best Cross-validation Accuracy: {study.best_value:.4f}\")\n",
        "\n",
        "# Train the final model with the best parameters on the training data\n",
        "best_params = study.best_params\n",
        "final_model = xgb.XGBClassifier(**best_params)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the original test set\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n",
        "# Evaluate the final model on the test set\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print test set performance metrics\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test Precision: {precision:.4f}\")\n",
        "print(f\"Test F1 Score: {f1:.4f}\")\n",
        "print(f\"Test Recall: {recall:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6VeeeDEaW2i",
        "outputId": "f0b9baf1-39bb-4af9-add9-2c38ec6609c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-08 11:06:22,361] A new study created in memory with name: no-name-62565383-176f-418a-95ff-caf9cae728a6\n",
            "[I 2025-01-08 11:06:23,187] Trial 0 finished with value: 0.9749466666666666 and parameters: {'booster': 'gbtree', 'learning_rate': 0.07444444444444444, 'gamma': 0.125, 'max_depth': 8, 'min_child_weight': 1.0, 'subsample': 0.7777777777777778, 'colsample_bytree': 0.5555555555555556, 'n_estimators': 160}. Best is trial 0 with value: 0.9749466666666666.\n",
            "[I 2025-01-08 11:06:31,641] Trial 1 finished with value: 0.9609333333333334 and parameters: {'booster': 'dart', 'learning_rate': 0.24673865411779808, 'gamma': 0.024884626335284432, 'max_depth': 6, 'min_child_weight': 3.177520155001819, 'subsample': 0.8587340395554446, 'colsample_bytree': 0.7669755818029269, 'n_estimators': 190}. Best is trial 0 with value: 0.9749466666666666.\n",
            "[I 2025-01-08 11:06:35,922] Trial 2 finished with value: 0.9669466666666666 and parameters: {'booster': 'dart', 'learning_rate': 0.043243806396596376, 'gamma': 0.20506529084442982, 'max_depth': 3, 'min_child_weight': 3.53463581759091, 'subsample': 0.5128503097516417, 'colsample_bytree': 0.7815421813138745, 'n_estimators': 160}. Best is trial 0 with value: 0.9749466666666666.\n",
            "[I 2025-01-08 11:06:36,282] Trial 3 finished with value: 0.9666399999999999 and parameters: {'booster': 'gbtree', 'learning_rate': 0.0445239208233834, 'gamma': 0.33299013089101986, 'max_depth': 7, 'min_child_weight': 2.4820229640028852, 'subsample': 0.5387228374929781, 'colsample_bytree': 0.8420323400642696, 'n_estimators': 142}. Best is trial 0 with value: 0.9749466666666666.\n",
            "[I 2025-01-08 11:06:45,976] Trial 4 finished with value: 0.9682000000000001 and parameters: {'booster': 'dart', 'learning_rate': 0.19538902432581845, 'gamma': 0.1745016935461532, 'max_depth': 10, 'min_child_weight': 1.6273713324872885, 'subsample': 0.6401556845209204, 'colsample_bytree': 0.6141068867592812, 'n_estimators': 210}. Best is trial 0 with value: 0.9749466666666666.\n",
            "[I 2025-01-08 11:06:57,554] Trial 5 finished with value: 0.9656533333333333 and parameters: {'booster': 'dart', 'learning_rate': 0.037816551128582, 'gamma': 0.3222724668857634, 'max_depth': 9, 'min_child_weight': 4.0352970499221925, 'subsample': 0.5254466591069211, 'colsample_bytree': 0.5383894680989536, 'n_estimators': 239}. Best is trial 0 with value: 0.9749466666666666.\n",
            "[I 2025-01-08 11:06:57,925] Trial 6 finished with value: 0.974 and parameters: {'booster': 'gbtree', 'learning_rate': 0.12931934116578175, 'gamma': 0.21022709103926285, 'max_depth': 4, 'min_child_weight': 1.5178081547109237, 'subsample': 0.9563233098529187, 'colsample_bytree': 0.5401617597279098, 'n_estimators': 217}. Best is trial 0 with value: 0.9749466666666666.\n",
            "[I 2025-01-08 11:07:12,435] Trial 7 finished with value: 0.9639999999999999 and parameters: {'booster': 'dart', 'learning_rate': 0.15805902123165405, 'gamma': 0.10716877175272882, 'max_depth': 5, 'min_child_weight': 1.2774642822046578, 'subsample': 0.6562341935525706, 'colsample_bytree': 0.5966671022623034, 'n_estimators': 275}. Best is trial 0 with value: 0.9749466666666666.\n",
            "[I 2025-01-08 11:07:13,522] Trial 8 finished with value: 0.9640133333333333 and parameters: {'booster': 'dart', 'learning_rate': 0.1258195678127335, 'gamma': 0.277420210097338, 'max_depth': 8, 'min_child_weight': 3.771525462808379, 'subsample': 0.9061831498699524, 'colsample_bytree': 0.5826805460375754, 'n_estimators': 74}. Best is trial 0 with value: 0.9749466666666666.\n",
            "[I 2025-01-08 11:07:13,737] Trial 9 finished with value: 0.9630133333333333 and parameters: {'booster': 'gbtree', 'learning_rate': 0.26354408738570806, 'gamma': 0.18722076484785594, 'max_depth': 7, 'min_child_weight': 4.265965808785369, 'subsample': 0.9940082659042178, 'colsample_bytree': 0.8955968937514652, 'n_estimators': 52}. Best is trial 0 with value: 0.9749466666666666.\n",
            "[I 2025-01-08 11:07:14,126] Trial 10 finished with value: 0.9729599999999999 and parameters: {'booster': 'gbtree', 'learning_rate': 0.09748960430772641, 'gamma': 0.46998588934932883, 'max_depth': 10, 'min_child_weight': 0.70879778876192, 'subsample': 0.7850250492518585, 'colsample_bytree': 0.6915761744511061, 'n_estimators': 116}. Best is trial 0 with value: 0.9749466666666666.\n",
            "[I 2025-01-08 11:07:14,582] Trial 11 finished with value: 0.9653733333333333 and parameters: {'booster': 'gbtree', 'learning_rate': 0.09886527474418813, 'gamma': 0.0674195585204134, 'max_depth': 3, 'min_child_weight': 2.1080199737204133, 'subsample': 0.966384864101126, 'colsample_bytree': 0.5080631603680943, 'n_estimators': 244}. Best is trial 0 with value: 0.9749466666666666.\n",
            "[I 2025-01-08 11:07:15,164] Trial 12 finished with value: 0.9758666666666667 and parameters: {'booster': 'gbtree', 'learning_rate': 0.18147668706108794, 'gamma': 0.0884354346172296, 'max_depth': 5, 'min_child_weight': 0.5670847699225021, 'subsample': 0.7848645063885442, 'colsample_bytree': 0.9966952046271562, 'n_estimators': 298}. Best is trial 12 with value: 0.9758666666666667.\n",
            "[I 2025-01-08 11:07:15,544] Trial 13 finished with value: 0.9755333333333333 and parameters: {'booster': 'gbtree', 'learning_rate': 0.2017846861278477, 'gamma': 0.11599722682041529, 'max_depth': 5, 'min_child_weight': 0.564701942764599, 'subsample': 0.7688447005837853, 'colsample_bytree': 0.9575902792425308, 'n_estimators': 117}. Best is trial 12 with value: 0.9758666666666667.\n",
            "[I 2025-01-08 11:07:16,139] Trial 14 finished with value: 0.9759066666666667 and parameters: {'booster': 'gbtree', 'learning_rate': 0.2046924081133806, 'gamma': 0.030492765470721134, 'max_depth': 5, 'min_child_weight': 0.5004683254261966, 'subsample': 0.7114377118600832, 'colsample_bytree': 0.9975087367815141, 'n_estimators': 290}. Best is trial 14 with value: 0.9759066666666667.\n",
            "[I 2025-01-08 11:07:16,567] Trial 15 finished with value: 0.96128 and parameters: {'booster': 'gbtree', 'learning_rate': 0.21027020791892456, 'gamma': 0.0011385593115329218, 'max_depth': 5, 'min_child_weight': 4.898567789422538, 'subsample': 0.7061623359307329, 'colsample_bytree': 0.9994512295750585, 'n_estimators': 298}. Best is trial 14 with value: 0.9759066666666667.\n",
            "[I 2025-01-08 11:07:17,124] Trial 16 finished with value: 0.9643333333333333 and parameters: {'booster': 'gbtree', 'learning_rate': 0.16361561824278675, 'gamma': 0.03986792102413557, 'max_depth': 6, 'min_child_weight': 2.0567764468160012, 'subsample': 0.8608090714538339, 'colsample_bytree': 0.9120898344150754, 'n_estimators': 297}. Best is trial 14 with value: 0.9759066666666667.\n",
            "[I 2025-01-08 11:07:17,645] Trial 17 finished with value: 0.9761599999999999 and parameters: {'booster': 'gbtree', 'learning_rate': 0.22945174400660368, 'gamma': 0.08060381115553433, 'max_depth': 4, 'min_child_weight': 0.5770746971156508, 'subsample': 0.6178407815041025, 'colsample_bytree': 0.9946132352882102, 'n_estimators': 263}. Best is trial 17 with value: 0.9761599999999999.\n",
            "[I 2025-01-08 11:07:19,366] Trial 18 finished with value: 0.9593599999999999 and parameters: {'booster': 'gbtree', 'learning_rate': 0.2971588298139566, 'gamma': 0.4341862009756779, 'max_depth': 4, 'min_child_weight': 2.8569293025072886, 'subsample': 0.6016873055231577, 'colsample_bytree': 0.8447626172295924, 'n_estimators': 261}. Best is trial 17 with value: 0.9761599999999999.\n",
            "[I 2025-01-08 11:07:21,077] Trial 19 finished with value: 0.9748933333333334 and parameters: {'booster': 'gbtree', 'learning_rate': 0.22564375937025807, 'gamma': 0.14820572192191872, 'max_depth': 4, 'min_child_weight': 1.1102870335521993, 'subsample': 0.6930994127395845, 'colsample_bytree': 0.931401448721636, 'n_estimators': 265}. Best is trial 17 with value: 0.9761599999999999.\n",
            "[I 2025-01-08 11:07:21,476] Trial 20 finished with value: 0.9605066666666667 and parameters: {'booster': 'gbtree', 'learning_rate': 0.2887393456306556, 'gamma': 0.06106638693328526, 'max_depth': 3, 'min_child_weight': 1.8959685987771304, 'subsample': 0.5868327143866063, 'colsample_bytree': 0.849669818755437, 'n_estimators': 233}. Best is trial 17 with value: 0.9761599999999999.\n",
            "[I 2025-01-08 11:07:22,048] Trial 21 finished with value: 0.9791733333333333 and parameters: {'booster': 'gbtree', 'learning_rate': 0.17381985302038921, 'gamma': 0.09462296233177214, 'max_depth': 5, 'min_child_weight': 0.573347885974969, 'subsample': 0.731521401285902, 'colsample_bytree': 0.9968978057776777, 'n_estimators': 283}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:07:22,544] Trial 22 finished with value: 0.9728933333333334 and parameters: {'booster': 'gbtree', 'learning_rate': 0.24053394322818047, 'gamma': 0.004543740178782077, 'max_depth': 4, 'min_child_weight': 0.9623498323493012, 'subsample': 0.7138011672378011, 'colsample_bytree': 0.9598212122772856, 'n_estimators': 274}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:07:23,027] Trial 23 finished with value: 0.9719466666666667 and parameters: {'booster': 'gbtree', 'learning_rate': 0.17253791124595363, 'gamma': 0.07419365789328969, 'max_depth': 6, 'min_child_weight': 1.4254533536770375, 'subsample': 0.6607494242582321, 'colsample_bytree': 0.9585050167277767, 'n_estimators': 255}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:07:23,546] Trial 24 finished with value: 0.9785600000000001 and parameters: {'booster': 'gbtree', 'learning_rate': 0.13864957364013997, 'gamma': 0.25054290136792934, 'max_depth': 5, 'min_child_weight': 0.5120553402685887, 'subsample': 0.7318323305282906, 'colsample_bytree': 0.8898812304963022, 'n_estimators': 212}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:07:24,009] Trial 25 finished with value: 0.9761866666666666 and parameters: {'booster': 'gbtree', 'learning_rate': 0.13643799897038256, 'gamma': 0.2651682415297005, 'max_depth': 4, 'min_child_weight': 1.0438463209002662, 'subsample': 0.8247867175249515, 'colsample_bytree': 0.8829041441661627, 'n_estimators': 204}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:07:24,511] Trial 26 finished with value: 0.9755066666666667 and parameters: {'booster': 'gbtree', 'learning_rate': 0.13422504850032685, 'gamma': 0.24858026814539488, 'max_depth': 6, 'min_child_weight': 0.935779702502258, 'subsample': 0.8381736747406258, 'colsample_bytree': 0.8768447087526715, 'n_estimators': 190}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:07:24,961] Trial 27 finished with value: 0.9679733333333334 and parameters: {'booster': 'gbtree', 'learning_rate': 0.09978959365056257, 'gamma': 0.3632420944499996, 'max_depth': 5, 'min_child_weight': 1.7613859167667867, 'subsample': 0.8250421320083272, 'colsample_bytree': 0.8016644430522479, 'n_estimators': 214}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:07:25,369] Trial 28 finished with value: 0.9623333333333333 and parameters: {'booster': 'gbtree', 'learning_rate': 0.14685788286149778, 'gamma': 0.2485056611116565, 'max_depth': 3, 'min_child_weight': 2.420416149054774, 'subsample': 0.7377053074120532, 'colsample_bytree': 0.6945445983333419, 'n_estimators': 187}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:07:25,859] Trial 29 finished with value: 0.9723066666666667 and parameters: {'booster': 'gbtree', 'learning_rate': 0.06151720883120963, 'gamma': 0.28865233964738346, 'max_depth': 7, 'min_child_weight': 0.9266071518821459, 'subsample': 0.9054017131724077, 'colsample_bytree': 0.7148259838155163, 'n_estimators': 164}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:07:26,270] Trial 30 finished with value: 0.97324 and parameters: {'booster': 'gbtree', 'learning_rate': 0.11187187539261939, 'gamma': 0.3840970496703071, 'max_depth': 4, 'min_child_weight': 1.1858235715464525, 'subsample': 0.8004224431497489, 'colsample_bytree': 0.8038706753806344, 'n_estimators': 135}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:07:26,758] Trial 31 finished with value: 0.9742266666666668 and parameters: {'booster': 'gbtree', 'learning_rate': 0.14317107666377454, 'gamma': 0.15149234799022393, 'max_depth': 4, 'min_child_weight': 0.8128990662861482, 'subsample': 0.7500427851184608, 'colsample_bytree': 0.9308496111215775, 'n_estimators': 228}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:07:27,327] Trial 32 finished with value: 0.9765333333333335 and parameters: {'booster': 'gbtree', 'learning_rate': 0.07878376881919076, 'gamma': 0.23728511748903375, 'max_depth': 4, 'min_child_weight': 0.7979556218566515, 'subsample': 0.6056219005471463, 'colsample_bytree': 0.8743210417876744, 'n_estimators': 200}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:07:27,823] Trial 33 finished with value: 0.9698799999999999 and parameters: {'booster': 'gbtree', 'learning_rate': 0.07516576848382119, 'gamma': 0.22436652315965921, 'max_depth': 6, 'min_child_weight': 1.2432755725692766, 'subsample': 0.5680520628892857, 'colsample_bytree': 0.8699533742862331, 'n_estimators': 199}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:07:35,761] Trial 34 finished with value: 0.9732933333333333 and parameters: {'booster': 'dart', 'learning_rate': 0.01214639058684816, 'gamma': 0.3002226689338998, 'max_depth': 3, 'min_child_weight': 0.8632783941859158, 'subsample': 0.8738385715370546, 'colsample_bytree': 0.7455489962102979, 'n_estimators': 174}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:07:36,201] Trial 35 finished with value: 0.9719466666666665 and parameters: {'booster': 'gbtree', 'learning_rate': 0.06622621835426859, 'gamma': 0.265229716509235, 'max_depth': 5, 'min_child_weight': 1.415073798593264, 'subsample': 0.67848107390882, 'colsample_bytree': 0.821542815995349, 'n_estimators': 148}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:07:42,967] Trial 36 finished with value: 0.9540000000000001 and parameters: {'booster': 'dart', 'learning_rate': 0.18673425323209042, 'gamma': 0.3467253856814513, 'max_depth': 4, 'min_child_weight': 3.186701779061575, 'subsample': 0.7439053586289502, 'colsample_bytree': 0.8957336414708714, 'n_estimators': 200}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:07:43,448] Trial 37 finished with value: 0.9735199999999999 and parameters: {'booster': 'gbtree', 'learning_rate': 0.11388331143803367, 'gamma': 0.2243165334268201, 'max_depth': 6, 'min_child_weight': 1.089583659683527, 'subsample': 0.8192327316720449, 'colsample_bytree': 0.7535535756151305, 'n_estimators': 221}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:07:51,289] Trial 38 finished with value: 0.96892 and parameters: {'booster': 'dart', 'learning_rate': 0.15925543165296727, 'gamma': 0.17970351023452416, 'max_depth': 3, 'min_child_weight': 1.592734018850722, 'subsample': 0.6284980687990819, 'colsample_bytree': 0.9312682649023323, 'n_estimators': 176}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:07:51,786] Trial 39 finished with value: 0.9722533333333334 and parameters: {'booster': 'gbtree', 'learning_rate': 0.08779411711697745, 'gamma': 0.31078109429814194, 'max_depth': 5, 'min_child_weight': 0.776521141206581, 'subsample': 0.5006817782470726, 'colsample_bytree': 0.8683050060116495, 'n_estimators': 208}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:08:04,132] Trial 40 finished with value: 0.9637066666666666 and parameters: {'booster': 'dart', 'learning_rate': 0.11920833687489411, 'gamma': 0.3845304577911033, 'max_depth': 7, 'min_child_weight': 2.243454291779834, 'subsample': 0.5410953718789413, 'colsample_bytree': 0.8131138076935402, 'n_estimators': 238}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:08:04,644] Trial 41 finished with value: 0.9758533333333332 and parameters: {'booster': 'gbtree', 'learning_rate': 0.26121580384828663, 'gamma': 0.15766868494536412, 'max_depth': 4, 'min_child_weight': 0.5153313233034189, 'subsample': 0.6179081341960749, 'colsample_bytree': 0.9676780044568836, 'n_estimators': 252}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:08:05,134] Trial 42 finished with value: 0.96584 and parameters: {'booster': 'gbtree', 'learning_rate': 0.22790853917811454, 'gamma': 0.13874188376412955, 'max_depth': 4, 'min_child_weight': 0.7132248042429291, 'subsample': 0.5562695260458671, 'colsample_bytree': 0.9055819631125531, 'n_estimators': 247}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:08:05,880] Trial 43 finished with value: 0.9752666666666666 and parameters: {'booster': 'gbtree', 'learning_rate': 0.027834734072724743, 'gamma': 0.20647354799522827, 'max_depth': 4, 'min_child_weight': 1.3190288146221305, 'subsample': 0.6510343594163697, 'colsample_bytree': 0.9647440205248998, 'n_estimators': 286}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:08:06,434] Trial 44 finished with value: 0.9774666666666667 and parameters: {'booster': 'gbtree', 'learning_rate': 0.13870795144740772, 'gamma': 0.10188697136559538, 'max_depth': 5, 'min_child_weight': 0.7293597142739656, 'subsample': 0.6761005206772482, 'colsample_bytree': 0.7742926053601921, 'n_estimators': 276}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:08:06,961] Trial 45 finished with value: 0.9739066666666666 and parameters: {'booster': 'gbtree', 'learning_rate': 0.13724716655207303, 'gamma': 0.18705405100298023, 'max_depth': 5, 'min_child_weight': 1.0685968042583527, 'subsample': 0.6722417824363947, 'colsample_bytree': 0.6560896988946039, 'n_estimators': 281}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:08:07,434] Trial 46 finished with value: 0.9758800000000001 and parameters: {'booster': 'gbtree', 'learning_rate': 0.17743564935827982, 'gamma': 0.12034551411615343, 'max_depth': 5, 'min_child_weight': 0.7297331972679089, 'subsample': 0.7278265200800879, 'colsample_bytree': 0.7656350239260832, 'n_estimators': 225}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:08:07,857] Trial 47 finished with value: 0.9719466666666665 and parameters: {'booster': 'gbtree', 'learning_rate': 0.1484994232369362, 'gamma': 0.09708714919871557, 'max_depth': 8, 'min_child_weight': 1.7185121974921371, 'subsample': 0.684963668275003, 'colsample_bytree': 0.7832874419776341, 'n_estimators': 182}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:08:08,395] Trial 48 finished with value: 0.9772399999999999 and parameters: {'booster': 'gbtree', 'learning_rate': 0.08323142197989801, 'gamma': 0.26462849785308096, 'max_depth': 5, 'min_child_weight': 0.7211114757895466, 'subsample': 0.767423257893423, 'colsample_bytree': 0.8340499964610371, 'n_estimators': 208}. Best is trial 21 with value: 0.9791733333333333.\n",
            "[I 2025-01-08 11:08:15,851] Trial 49 finished with value: 0.9778399999999999 and parameters: {'booster': 'dart', 'learning_rate': 0.0824655381275111, 'gamma': 0.23063352103942789, 'max_depth': 6, 'min_child_weight': 0.723466002553554, 'subsample': 0.7641369959115688, 'colsample_bytree': 0.8351248218102408, 'n_estimators': 167}. Best is trial 21 with value: 0.9791733333333333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'booster': 'gbtree', 'learning_rate': 0.17381985302038921, 'gamma': 0.09462296233177214, 'max_depth': 5, 'min_child_weight': 0.573347885974969, 'subsample': 0.731521401285902, 'colsample_bytree': 0.9968978057776777, 'n_estimators': 283}\n",
            "Best Cross-validation Accuracy: 0.9792\n",
            "Test Accuracy: 0.8545\n",
            "Test Precision: 0.8545\n",
            "Test F1 Score: 0.8545\n",
            "Test Recall: 0.8545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = X_train.columns.tolist()\n",
        "\n",
        "# Best parameters from Bayesian Optimization XGBoost\n",
        "best_params_xg = {\n",
        "    'learning_rate': 0.17381985302038921,\n",
        "    'max_depth': 5,\n",
        "    'n_estimators':  283,\n",
        "    'gamma':0.09462296233177214,\n",
        "    'min_child_weight': 0.573347885974969,\n",
        "    'subsample': 0.731521401285902,\n",
        "    'colsample_bytree':0.9968978057776777,\n",
        "    'objective': 'binary:logistic',\n",
        "    'booster': 'gbtree',\n",
        "}\n",
        "\n",
        "# Create the XGBoost classifier with the best parameters\n",
        "final_model_xg = xgb.XGBClassifier(**best_params_xg)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(final_model_xg, X_train[selected_features], y_train, cv=5, scoring='roc_auc')\n",
        "print(\"Cross-validation scores:\")\n",
        "print(cv_scores)\n",
        "print(f\"Mean CV accuracy: {np.mean(cv_scores):.4f}\")\n",
        "\n",
        "# Train the model\n",
        "final_model_xg.fit(X_train[selected_features], y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_xg = final_model_xg.predict(X_test[selected_features])\n",
        "y_pred_prob_xg = final_model_xg.predict_proba(X_test[selected_features])[:, 1]\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_xg)\n",
        "precision = precision_score(y_test, y_pred_xg, average = 'weighted')\n",
        "recall = recall_score(y_test, y_pred_xg, average = 'weighted')\n",
        "f1 = f1_score(y_test, y_pred_xg, average = 'weighted')\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob_xg)\n",
        "\n",
        "# Calculate specificity\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_xg).ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "# Print the results\n",
        "print(f'Test ROC AUC: {roc_auc:.2f}')\n",
        "print(f'Test Accuracy: {accuracy:.2f}')\n",
        "print(f'Test Precision: {precision:.2f}')\n",
        "print(f'Test Recall: {recall:.2f}')\n",
        "print(f'Test F1-Score: {f1:.2f}')\n",
        "print(f'Test Specificity: {specificity:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Qq3Hin9d2iB",
        "outputId": "b649d1ab-a498-4e10-dc09-9720f3504905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores:\n",
            "[0.9392     0.99833333 0.99166667 0.97666667 0.99      ]\n",
            "Mean CV accuracy: 0.9792\n",
            "Test ROC AUC: 0.86\n",
            "Test Accuracy: 0.85\n",
            "Test Precision: 0.85\n",
            "Test Recall: 0.85\n",
            "Test F1-Score: 0.85\n",
            "Test Specificity: 0.71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##XGBoost Validation"
      ],
      "metadata": {
        "id": "v2krwBfB4shu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_val_ibd = gene_ibd.drop('Group', axis=1)\n",
        "y_val_ibd = gene_ibd['Group']\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y_val_ibd)\n",
        "\n",
        "# Assuming you have the feature names used in training saved\n",
        "missing_features = [feature for feature in selected_features if feature not in X_val_ibd.columns]\n",
        "\n",
        "# Add the missing features to the validation set with zero values\n",
        "missing_df = pd.DataFrame(0.0, index=X_val_ibd.index, columns=missing_features)\n",
        "X_val_ibd = pd.concat([X_val_ibd, missing_df], axis=1)\n",
        "\n",
        "# Ensure the columns are in the same order as the training features\n",
        "X_val_ibd = X_val_ibd[selected_features]\n",
        "\n",
        "#Make predictions on the validation set\n",
        "y_pred_prob_xg_ibd= final_model_xg.predict_proba(X_val_ibd)[:, 1]\n",
        "y_pred_xg_ibd = final_model_xg.predict(X_val_ibd)\n",
        "\n",
        "# Use the encoded labels for all metrics\n",
        "y_val_ibd_encoded = label_encoder.transform(y_val_ibd)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_val = accuracy_score(y_val_ibd_encoded, y_pred_xg_ibd)\n",
        "precision_val = precision_score(y_val_ibd_encoded, y_pred_xg_ibd, average=\"weighted\", zero_division=1)\n",
        "recall_val = recall_score(y_val_ibd_encoded, y_pred_xg_ibd, average=\"weighted\")\n",
        "f1_val = f1_score(y_val_ibd_encoded, y_pred_xg_ibd, average=\"weighted\")\n",
        "roc_auc_val = roc_auc_score(y_encoded, y_pred_prob_xg_ibd)\n",
        "\n",
        "# Calculate specificity\n",
        "tn_val, fp_val, fn_val, tp_val = confusion_matrix(y_val_ibd_encoded, y_pred_xg_ibd).ravel()\n",
        "specificity_val = tn_val / (tn_val + fp_val)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f'Validation ROC AUC: {roc_auc_val:.2f}')\n",
        "print(f'Validation Accuracy: {accuracy_val:.2f}')\n",
        "print(f'Validation Precision: {precision_val:.2f}')\n",
        "print(f'Validation Recall: {recall_val:.2f}')\n",
        "print(f'Validation F1-Score: {f1_val:.2f}')\n",
        "print(f'Validation Specificity: {specificity_val:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehIRr-bM5uLP",
        "outputId": "70afdd23-8702-4d91-b001-37bbac03637c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation ROC AUC: 0.55\n",
            "Validation Accuracy: 0.74\n",
            "Validation Precision: 0.73\n",
            "Validation Recall: 0.74\n",
            "Validation F1-Score: 0.74\n",
            "Validation Specificity: 0.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##95% CI"
      ],
      "metadata": {
        "id": "kCgESUbAU4ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate all metrics\n",
        "def calculate_metrics(y_true, y_pred, y_pred_prob):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average=\"weighted\", zero_division=1)\n",
        "    recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
        "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_prob)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    return accuracy, precision, recall, f1, roc_auc, specificity\n",
        "\n",
        "# Bootstrapping to calculate 95% CI\n",
        "n_iterations = 1000\n",
        "metrics = np.zeros((n_iterations, 6))\n",
        "\n",
        "for i in range(n_iterations):\n",
        "    X_resampled, y_resampled = resample(X_val_ibd, y_val_ibd_encoded, random_state=i)\n",
        "    y_pred_prob_resampled = final_model_xg.predict_proba(X_resampled)[:, 1]\n",
        "    y_pred_resampled = final_model_xg.predict(X_resampled)\n",
        "    metrics[i] = calculate_metrics(y_resampled, y_pred_resampled, y_pred_prob_resampled)\n",
        "\n",
        "# Calculate the 2.5th and 97.5th percentiles for each metric\n",
        "confidence_intervals = np.percentile(metrics, [2.5, 97.5], axis=0)\n",
        "\n",
        "# Display the metrics with their CIs\n",
        "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC AUC', 'Specificity']\n",
        "\n",
        "for i, name in enumerate(metrics_names):\n",
        "    print(f'{name}: (95% CI: {confidence_intervals[0, i]:.2f} - {confidence_intervals[1, i]:.2f})')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_YqyfKTJQFa",
        "outputId": "c205257b-938f-4811-fd73-203d6e941a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: (95% CI: 0.70 - 0.79)\n",
            "Precision: (95% CI: 0.65 - 0.80)\n",
            "Recall: (95% CI: 0.70 - 0.79)\n",
            "F1-Score: (95% CI: 0.70 - 0.79)\n",
            "ROC AUC: (95% CI: 0.48 - 0.62)\n",
            "Specificity: (95% CI: 0.04 - 0.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest"
      ],
      "metadata": {
        "id": "gjI8m9_Z3B7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = gene.drop(['Group'], axis=1)\n",
        "y = gene['Group']\n",
        "\n",
        "# Encode categorical target labels into numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Create the Random Forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy on the test set\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "# Calculate F1 score on the test set\n",
        "test_f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Test F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# Calculate precision on the test set\n",
        "test_precision = precision_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Test Precision: {test_precision:.2f}\")\n",
        "\n",
        "# Calculate recall on the test set\n",
        "test_recall = recall_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Test Recall: {test_recall:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTcF3TU4JuE7",
        "outputId": "d6177351-b4aa-4f31-ccea-640844ff28dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.84\n",
            "Test F1 Score: 0.84\n",
            "Test Precision: 0.84\n",
            "Test Recall: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random Search"
      ],
      "metadata": {
        "id": "fjIuEoYnKPLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Define the parameter distribution for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'rf__n_estimators': [int(x) for x in np.linspace(start=200, stop=2000, num=10)],\n",
        "    'rf__max_features': ['sqrt', 'log2'],\n",
        "    'rf__max_depth': [int(x) for x in np.linspace(10, 300, num=20)] + [None],\n",
        "    'rf__min_samples_split': [2, 5, 10, 15],\n",
        "    'rf__min_samples_leaf': [1, 2, 4, 6],\n",
        "    'rf__bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Initialize the pipeline: Random Forest\n",
        "pipeline = Pipeline([\n",
        "    ('rf', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "rf_random = RandomizedSearchCV(estimator=pipeline, param_distributions=param_dist,\n",
        "                               n_iter=100, cv=StratifiedKFold(5), verbose=2,\n",
        "                               random_state=42, n_jobs=-1, scoring='roc_auc')\n",
        "\n",
        "# Fit RandomizedSearchCV to the original training data\n",
        "rf_random.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found by RandomizedSearchCV\n",
        "print(\"Best parameters found by RandomizedSearchCV:\")\n",
        "print(rf_random.best_params_)\n",
        "\n",
        "# Predict on the original test data\n",
        "y_pred = rf_random.best_estimator_.predict(X_test)\n",
        "y_prob = rf_random.best_estimator_.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate the model with default threshold\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g076no6KOAZ",
        "outputId": "432bd56f-b4a1-4090-9e5f-573b7d88ffa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "Best parameters found by RandomizedSearchCV:\n",
            "{'rf__n_estimators': 200, 'rf__min_samples_split': 10, 'rf__min_samples_leaf': 1, 'rf__max_features': 'sqrt', 'rf__max_depth': None, 'rf__bootstrap': True}\n",
            "Accuracy: 0.8182\n",
            "Precision: 0.8281\n",
            "Recall: 0.8182\n",
            "F1 Score: 0.8220\n",
            "ROC AUC: 0.8833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bayesian Optimization"
      ],
      "metadata": {
        "id": "NV9B0tvfihJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the best parameters found from RandomizedSearchCV RF\n",
        "best_params_random = {\n",
        "    'n_estimators': 200,\n",
        "    'min_samples_split':10,\n",
        "    'min_samples_leaf':1,\n",
        "    'max_features': 'sqrt',\n",
        "    'max_depth': None,\n",
        "    'bootstrap': True,\n",
        "    'class_weight': 'balanced'\n",
        "}\n",
        "\n",
        "def objective(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', max(100, best_params_random['n_estimators'] - 200), best_params_random['n_estimators'] + 200)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', max(2, best_params_random['min_samples_split'] - 3), best_params_random['min_samples_split'] + 3)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', max(1, best_params_random['min_samples_leaf'] - 2), best_params_random['min_samples_leaf'] + 2)\n",
        "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2'])\n",
        "    max_depth = trial.suggest_categorical('max_depth', [None, 10, 25, 162, 300])\n",
        "    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
        "    class_weight = trial.suggest_categorical('class_weight', ['balanced', None])\n",
        "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
        "    min_impurity_decrease = trial.suggest_float('min_impurity_decrease', 0.0, 0.01)\n",
        "\n",
        "    # Initialize RandomForestClassifier with suggested hyperparameters\n",
        "    clf = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        max_features=max_features,\n",
        "        max_depth=max_depth,\n",
        "        bootstrap=bootstrap,\n",
        "        class_weight=class_weight,\n",
        "        criterion=criterion,\n",
        "        min_impurity_decrease=min_impurity_decrease,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Use cross-validation to evaluate the classifier\n",
        "    cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='roc_auc')\n",
        "    return np.mean(cv_scores)\n",
        "\n",
        "# Perform optimization with Optuna\n",
        "study = optuna.create_study(direction='maximize')\n",
        "\n",
        "# Enqueue the trial with the best parameters from RandomizedSearchCV\n",
        "study.enqueue_trial(best_params_random)\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Print the best parameters and best score from Optuna\n",
        "print(\"Best Parameters from Optuna:\", study.best_params)\n",
        "print(\"Best F1-Weighted Score from Optuna:\", study.best_value)\n",
        "\n",
        "# Retrieve the best model and evaluate on the test set\n",
        "best_params_optuna = study.best_params\n",
        "best_clf = RandomForestClassifier(**best_params_optuna, random_state=50)\n",
        "best_clf.fit(X_train, y_train)\n",
        "y_pred = best_clf.predict(X_test)\n",
        "y_prob = best_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate on test set\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test Precision: {precision:.4f}\")\n",
        "print(f\"Test Recall: {recall:.4f}\")\n",
        "print(f\"Test F1 Score: {f1:.4f}\")\n",
        "print(f\"Test ROC AUC: {roc_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZzMDqz-BpDu",
        "outputId": "523c0685-416c-44ef-d288-c7ab176c8128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-08 12:13:38,560] A new study created in memory with name: no-name-6c0ad1d0-1d46-4567-8835-108bbffcd569\n",
            "[I 2025-01-08 12:13:40,267] Trial 0 finished with value: 0.9768533333333332 and parameters: {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'entropy', 'min_impurity_decrease': 0.0035874194207065092}. Best is trial 0 with value: 0.9768533333333332.\n",
            "[I 2025-01-08 12:13:42,142] Trial 1 finished with value: 0.9751733333333334 and parameters: {'n_estimators': 226, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_depth': 10, 'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'entropy', 'min_impurity_decrease': 0.007086237301015272}. Best is trial 0 with value: 0.9768533333333332.\n",
            "[I 2025-01-08 12:13:45,097] Trial 2 finished with value: 0.9698666666666667 and parameters: {'n_estimators': 368, 'min_samples_split': 11, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_depth': 300, 'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'min_impurity_decrease': 0.0059063476578185906}. Best is trial 0 with value: 0.9768533333333332.\n",
            "[I 2025-01-08 12:13:48,223] Trial 3 finished with value: 0.9705199999999999 and parameters: {'n_estimators': 285, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 300, 'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'min_impurity_decrease': 0.005852360004249692}. Best is trial 0 with value: 0.9768533333333332.\n",
            "[I 2025-01-08 12:13:49,188] Trial 4 finished with value: 0.97184 and parameters: {'n_estimators': 112, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_depth': 300, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.0028736481086584988}. Best is trial 0 with value: 0.9768533333333332.\n",
            "[I 2025-01-08 12:13:51,097] Trial 5 finished with value: 0.9735733333333332 and parameters: {'n_estimators': 241, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_depth': 300, 'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'entropy', 'min_impurity_decrease': 0.0014395891249694927}. Best is trial 0 with value: 0.9768533333333332.\n",
            "[I 2025-01-08 12:13:53,445] Trial 6 finished with value: 0.9771466666666667 and parameters: {'n_estimators': 283, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 300, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.004272052196360691}. Best is trial 6 with value: 0.9771466666666667.\n",
            "[I 2025-01-08 12:13:55,075] Trial 7 finished with value: 0.9699066666666667 and parameters: {'n_estimators': 224, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 162, 'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'min_impurity_decrease': 0.009637422581513167}. Best is trial 6 with value: 0.9771466666666667.\n",
            "[I 2025-01-08 12:13:58,479] Trial 8 finished with value: 0.9755333333333333 and parameters: {'n_estimators': 395, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_depth': 25, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.008147831374034463}. Best is trial 6 with value: 0.9771466666666667.\n",
            "[I 2025-01-08 12:14:00,617] Trial 9 finished with value: 0.9692533333333333 and parameters: {'n_estimators': 204, 'min_samples_split': 11, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_depth': None, 'bootstrap': False, 'class_weight': None, 'criterion': 'gini', 'min_impurity_decrease': 0.004820379272237411}. Best is trial 6 with value: 0.9771466666666667.\n",
            "[I 2025-01-08 12:14:03,676] Trial 10 finished with value: 0.9764933333333333 and parameters: {'n_estimators': 319, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 10, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.0006401491439616395}. Best is trial 6 with value: 0.9771466666666667.\n",
            "[I 2025-01-08 12:14:05,094] Trial 11 finished with value: 0.9752133333333333 and parameters: {'n_estimators': 164, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.0036851236790906954}. Best is trial 6 with value: 0.9771466666666667.\n",
            "[I 2025-01-08 12:14:07,536] Trial 12 finished with value: 0.9771466666666667 and parameters: {'n_estimators': 290, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.003715825167346168}. Best is trial 6 with value: 0.9771466666666667.\n",
            "[I 2025-01-08 12:14:10,057] Trial 13 finished with value: 0.9778133333333333 and parameters: {'n_estimators': 301, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 162, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.0019645367218804628}. Best is trial 13 with value: 0.9778133333333333.\n",
            "[I 2025-01-08 12:14:13,381] Trial 14 finished with value: 0.9765066666666666 and parameters: {'n_estimators': 320, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 162, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.0018122888467140231}. Best is trial 13 with value: 0.9778133333333333.\n",
            "[I 2025-01-08 12:14:16,283] Trial 15 finished with value: 0.9774799999999999 and parameters: {'n_estimators': 277, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 162, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 8.30262055432629e-05}. Best is trial 13 with value: 0.9778133333333333.\n",
            "[I 2025-01-08 12:14:19,155] Trial 16 finished with value: 0.9771599999999999 and parameters: {'n_estimators': 342, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 162, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.0003469072473213345}. Best is trial 13 with value: 0.9778133333333333.\n",
            "[I 2025-01-08 12:14:22,125] Trial 17 finished with value: 0.9758666666666667 and parameters: {'n_estimators': 264, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 162, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.0022834710744653462}. Best is trial 13 with value: 0.9778133333333333.\n",
            "[I 2025-01-08 12:14:30,723] Trial 18 finished with value: 0.9771333333333333 and parameters: {'n_estimators': 322, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 162, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'min_impurity_decrease': 0.00024198698340633165}. Best is trial 13 with value: 0.9778133333333333.\n",
            "[I 2025-01-08 12:14:33,793] Trial 19 finished with value: 0.9768266666666667 and parameters: {'n_estimators': 163, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 25, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.001438240273201016}. Best is trial 13 with value: 0.9778133333333333.\n",
            "[I 2025-01-08 12:14:36,812] Trial 20 finished with value: 0.9768266666666665 and parameters: {'n_estimators': 364, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 162, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.002644130506209822}. Best is trial 13 with value: 0.9778133333333333.\n",
            "[I 2025-01-08 12:14:40,295] Trial 21 finished with value: 0.9771599999999999 and parameters: {'n_estimators': 362, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 162, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 8.320323296688136e-05}. Best is trial 13 with value: 0.9778133333333333.\n",
            "[I 2025-01-08 12:14:43,915] Trial 22 finished with value: 0.9765066666666666 and parameters: {'n_estimators': 336, 'min_samples_split': 13, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 162, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.000977493378424623}. Best is trial 13 with value: 0.9778133333333333.\n",
            "[I 2025-01-08 12:14:46,425] Trial 23 finished with value: 0.9771466666666667 and parameters: {'n_estimators': 302, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 162, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 5.038466948724656e-05}. Best is trial 13 with value: 0.9778133333333333.\n",
            "[I 2025-01-08 12:14:48,599] Trial 24 finished with value: 0.9781466666666667 and parameters: {'n_estimators': 258, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 162, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.0010315538149661327}. Best is trial 24 with value: 0.9781466666666667.\n",
            "[I 2025-01-08 12:14:51,357] Trial 25 finished with value: 0.9761866666666666 and parameters: {'n_estimators': 258, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 162, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.0020653267554970336}. Best is trial 24 with value: 0.9781466666666667.\n",
            "[I 2025-01-08 12:14:53,662] Trial 26 finished with value: 0.9724933333333334 and parameters: {'n_estimators': 262, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 10, 'bootstrap': False, 'class_weight': None, 'criterion': 'gini', 'min_impurity_decrease': 0.001123359829623706}. Best is trial 24 with value: 0.9781466666666667.\n",
            "[I 2025-01-08 12:14:57,113] Trial 27 finished with value: 0.9771599999999999 and parameters: {'n_estimators': 304, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 162, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.0027590720333762514}. Best is trial 24 with value: 0.9781466666666667.\n",
            "[I 2025-01-08 12:14:59,145] Trial 28 finished with value: 0.9764933333333333 and parameters: {'n_estimators': 241, 'min_samples_split': 11, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 25, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.000954949752791911}. Best is trial 24 with value: 0.9781466666666667.\n",
            "[I 2025-01-08 12:15:00,754] Trial 29 finished with value: 0.9761733333333333 and parameters: {'n_estimators': 189, 'min_samples_split': 13, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 162, 'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'entropy', 'min_impurity_decrease': 0.003242339587564283}. Best is trial 24 with value: 0.9781466666666667.\n",
            "[I 2025-01-08 12:15:02,543] Trial 30 finished with value: 0.9764933333333333 and parameters: {'n_estimators': 208, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 162, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.0018602410961020104}. Best is trial 24 with value: 0.9781466666666667.\n",
            "[I 2025-01-08 12:15:05,470] Trial 31 finished with value: 0.9771599999999999 and parameters: {'n_estimators': 350, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 162, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.0009478426829963599}. Best is trial 24 with value: 0.9781466666666667.\n",
            "[I 2025-01-08 12:15:08,855] Trial 32 finished with value: 0.9778133333333333 and parameters: {'n_estimators': 273, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 162, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.00041235097987662973}. Best is trial 24 with value: 0.9781466666666667.\n",
            "[I 2025-01-08 12:15:11,357] Trial 33 finished with value: 0.9771466666666667 and parameters: {'n_estimators': 270, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'min_impurity_decrease': 0.0014447454016067334}. Best is trial 24 with value: 0.9781466666666667.\n",
            "[I 2025-01-08 12:15:13,257] Trial 34 finished with value: 0.9781466666666667 and parameters: {'n_estimators': 225, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 162, 'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'entropy', 'min_impurity_decrease': 0.0006378956153172371}. Best is trial 24 with value: 0.9781466666666667.\n",
            "[I 2025-01-08 12:15:15,013] Trial 35 finished with value: 0.97288 and parameters: {'n_estimators': 231, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 162, 'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'min_impurity_decrease': 0.005392406476633058}. Best is trial 24 with value: 0.9781466666666667.\n",
            "[I 2025-01-08 12:15:16,619] Trial 36 finished with value: 0.97584 and parameters: {'n_estimators': 184, 'min_samples_split': 13, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 162, 'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'entropy', 'min_impurity_decrease': 0.0066253087961511995}. Best is trial 24 with value: 0.9781466666666667.\n",
            "[I 2025-01-08 12:15:18,702] Trial 37 finished with value: 0.9771599999999999 and parameters: {'n_estimators': 247, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 300, 'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'entropy', 'min_impurity_decrease': 0.0023145166070132808}. Best is trial 24 with value: 0.9781466666666667.\n",
            "[I 2025-01-08 12:15:21,851] Trial 38 finished with value: 0.9797733333333334 and parameters: {'n_estimators': 297, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 25, 'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'min_impurity_decrease': 0.0006757439382742002}. Best is trial 38 with value: 0.9797733333333334.\n",
            "[I 2025-01-08 12:15:24,447] Trial 39 finished with value: 0.9771466666666667 and parameters: {'n_estimators': 298, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 25, 'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'min_impurity_decrease': 0.004108144839236908}. Best is trial 38 with value: 0.9797733333333334.\n",
            "[I 2025-01-08 12:15:26,128] Trial 40 finished with value: 0.9755733333333334 and parameters: {'n_estimators': 222, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 25, 'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'min_impurity_decrease': 0.003006406438090595}. Best is trial 38 with value: 0.9797733333333334.\n",
            "[I 2025-01-08 12:15:28,299] Trial 41 finished with value: 0.9798133333333332 and parameters: {'n_estimators': 281, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 25, 'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'min_impurity_decrease': 0.0006397360582877326}. Best is trial 41 with value: 0.9798133333333332.\n",
            "[I 2025-01-08 12:15:30,702] Trial 42 finished with value: 0.98012 and parameters: {'n_estimators': 312, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 25, 'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'min_impurity_decrease': 0.0015796705503652985}. Best is trial 42 with value: 0.98012.\n",
            "[I 2025-01-08 12:15:32,637] Trial 43 finished with value: 0.9804666666666666 and parameters: {'n_estimators': 249, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 25, 'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'min_impurity_decrease': 0.0014400188813810098}. Best is trial 43 with value: 0.9804666666666666.\n",
            "[I 2025-01-08 12:15:36,034] Trial 44 finished with value: 0.9801333333333334 and parameters: {'n_estimators': 286, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 25, 'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'min_impurity_decrease': 0.0014904082741382487}. Best is trial 43 with value: 0.9804666666666666.\n",
            "[I 2025-01-08 12:15:38,411] Trial 45 finished with value: 0.9797866666666666 and parameters: {'n_estimators': 287, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 25, 'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'min_impurity_decrease': 0.0016590672683045947}. Best is trial 43 with value: 0.9804666666666666.\n",
            "[I 2025-01-08 12:15:41,332] Trial 46 finished with value: 0.9791466666666666 and parameters: {'n_estimators': 384, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 25, 'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'min_impurity_decrease': 0.0015086115448671056}. Best is trial 43 with value: 0.9804666666666666.\n",
            "[I 2025-01-08 12:15:43,588] Trial 47 finished with value: 0.9731866666666665 and parameters: {'n_estimators': 284, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 25, 'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'min_impurity_decrease': 0.008410605260420824}. Best is trial 43 with value: 0.9804666666666666.\n",
            "[I 2025-01-08 12:15:46,029] Trial 48 finished with value: 0.9788 and parameters: {'n_estimators': 320, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 25, 'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'min_impurity_decrease': 0.003403828325170624}. Best is trial 43 with value: 0.9804666666666666.\n",
            "[I 2025-01-08 12:15:49,737] Trial 49 finished with value: 0.9728399999999999 and parameters: {'n_estimators': 334, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 25, 'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'min_impurity_decrease': 0.002655618553871429}. Best is trial 43 with value: 0.9804666666666666.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters from Optuna: {'n_estimators': 249, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 25, 'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'min_impurity_decrease': 0.0014400188813810098}\n",
            "Best F1-Weighted Score from Optuna: 0.9804666666666666\n",
            "Test Accuracy: 0.8545\n",
            "Test Precision: 0.8545\n",
            "Test Recall: 0.8545\n",
            "Test F1 Score: 0.8545\n",
            "Test ROC AUC: 0.8763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features_rf = X_train.columns.tolist()\n",
        "\n",
        "# Best parameters from Bayesian Optimization RF\n",
        "best_params_rf = {\n",
        "    'n_estimators': 249,\n",
        "    'min_samples_split': 8,\n",
        "    'min_samples_leaf': 1,\n",
        "    'max_features': 'sqrt',\n",
        "    'bootstrap': False,\n",
        "    'criterion': 'gini',\n",
        "    'max_depth': 25,\n",
        "    'min_impurity_decrease':0.0014400188813810098\n",
        "}\n",
        "\n",
        "\n",
        "## Create the Random Forest classifier with the best parameters\n",
        "final_model_rf = RandomForestClassifier(**best_params_rf, random_state=50)\n",
        "\n",
        "\n",
        "# Perform cross-validation with 5 folds\n",
        "cv_scores = cross_val_score(final_model_rf, X_train[selected_features_rf], y_train, cv=5, scoring='roc_auc')\n",
        "print(\"Cross-validation scores:\")\n",
        "print(cv_scores)\n",
        "print(f\"Mean CV accuracy: {np.mean(cv_scores):.4f}\")\n",
        "\n",
        "# Train the final model on the entire training data\n",
        "final_model_rf.fit(X_train[selected_features_rf], y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_rf = final_model_rf.predict(X_test[selected_features_rf])\n",
        "y_pred_prob_rf = final_model_rf.predict_proba(X_test[selected_features_rf])[:, 1]\n",
        "\n",
        "# Calculate evaluation metrics on the test set\n",
        "accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "precision = precision_score(y_test, y_pred_rf, average = 'weighted')\n",
        "recall = recall_score(y_test, y_pred_rf, average = 'weighted')\n",
        "f1 = f1_score(y_test, y_pred_rf, average = 'weighted')\n",
        "auc_roc = roc_auc_score(y_test, y_pred_prob_rf)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "# Print the results for test data\n",
        "print(f'Test Accuracy: {accuracy:.2f}')\n",
        "print(f'Test Precision: {precision:.2f}')\n",
        "print(f'Test Recall: {recall:.2f}')\n",
        "print(f'Test F1-Score: {f1:.2f}')\n",
        "print(f'Test AUC-ROC: {auc_roc:.2f}')\n",
        "print(f'Test Specificity: {specificity:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQyePtN0RtGu",
        "outputId": "fa8f784b-f292-4f2c-ca37-8275037bfb7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores:\n",
            "[0.9568     0.96       0.99       0.99       0.99833333]\n",
            "Mean CV accuracy: 0.9790\n",
            "Test Accuracy: 0.80\n",
            "Test Precision: 0.80\n",
            "Test Recall: 0.80\n",
            "Test F1-Score: 0.80\n",
            "Test AUC-ROC: 0.86\n",
            "Test Specificity: 0.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random Forest Validation"
      ],
      "metadata": {
        "id": "DZEG5fQXsHio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_val_ibd_rf = gene_ibd.drop('Group', axis=1)\n",
        "y_val_ibd_rf = gene_ibd['Group']\n",
        "\n",
        "# Encode categorical target labels into numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y_val_ibd_rf)\n",
        "\n",
        "# Identify the features that are missing in the validation set\n",
        "missing_features = [feature for feature in selected_features_rf if feature not in X_val_ibd_rf.columns]\n",
        "\n",
        "# Add the missing features to the validation set with zero values using pd.concat\n",
        "missing_df_rf = pd.DataFrame(0, index=X_val_ibd_rf.index, columns=missing_features)\n",
        "X_val_ibd_rf = pd.concat([X_val_ibd_rf, missing_df_rf], axis=1)\n",
        "\n",
        "# Ensure the columns are in the same order as the training features\n",
        "X_val_ibd_rf = X_val_ibd_rf[selected_features_rf]\n",
        "\n",
        "# Make predictions on the validation set without converting to NumPy array\n",
        "y_pred_prob_rf_ibd = final_model_rf.predict_proba(X_val_ibd_rf)[:, 1]\n",
        "y_pred_rf_ibd = final_model_rf.predict(X_val_ibd_rf)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_val = accuracy_score(y_encoded, y_pred_rf_ibd)\n",
        "precision_val = precision_score(y_encoded, y_pred_rf_ibd, average='weighted', zero_division=1)\n",
        "recall_val = recall_score(y_encoded, y_pred_rf_ibd, average='weighted')\n",
        "f1_val = f1_score(y_encoded, y_pred_rf_ibd, average='weighted')\n",
        "roc_auc_val = roc_auc_score(y_encoded, y_pred_prob_rf_ibd)\n",
        "\n",
        "# Calculate specificity\n",
        "tn_val, fp_val, fn_val, tp_val = confusion_matrix(y_encoded, y_pred_rf_ibd).ravel()\n",
        "specificity_val = tn_val / (tn_val + fp_val)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f'Validation ROC AUC: {roc_auc_val:.2f}')\n",
        "print(f'Validation Accuracy: {accuracy_val:.2f}')\n",
        "print(f'Validation Precision: {precision_val:.2f}')\n",
        "print(f'Validation Recall: {recall_val:.2f}')\n",
        "print(f'Validation F1-Score: {f1_val:.2f}')\n",
        "print(f'Validation Specificity: {specificity_val:.2f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEVuh8LnxUS8",
        "outputId": "cf7ba341-478c-44ac-9337-e7be3db506a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation ROC AUC: 0.57\n",
            "Validation Accuracy: 0.74\n",
            "Validation Precision: 0.72\n",
            "Validation Recall: 0.74\n",
            "Validation F1-Score: 0.74\n",
            "Validation Specificity: 0.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##95% CI"
      ],
      "metadata": {
        "id": "Cer4TwiOj3Ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute metrics\n",
        "def compute_metrics(y_true, y_pred, y_pred_proba):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=1)\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "    # Confusion matrix to compute specificity\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    return accuracy, precision, recall, f1, roc_auc, specificity\n",
        "\n",
        "# Number of bootstrap iterations\n",
        "n_iterations = 1000\n",
        "n_size = len(X_val_ibd_rf)\n",
        "\n",
        "# Initialize lists to store metric values for each bootstrap sample\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "roc_auc_scores = []\n",
        "specificity_scores = []\n",
        "\n",
        "# Bootstrap procedure\n",
        "for i in range(n_iterations):\n",
        "    # Resample the validation set with replacement\n",
        "    X_resample, y_resample = resample(X_val_ibd_rf, y_encoded, n_samples=n_size, random_state=i)\n",
        "\n",
        "    # Make predictions on the resampled data\n",
        "    y_pred_resample = final_model_rf.predict(X_resample)\n",
        "    y_pred_proba_resample = final_model_rf.predict_proba(X_resample)[:, 1]\n",
        "\n",
        "    # Calculate metrics for this bootstrap sample\n",
        "    accuracy, precision, recall, f1, roc_auc, specificity = compute_metrics(y_resample, y_pred_resample, y_pred_proba_resample)\n",
        "\n",
        "    # Store the metrics\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "    roc_auc_scores.append(roc_auc)\n",
        "    specificity_scores.append(specificity)\n",
        "\n",
        "# Calculate 95% confidence intervals for each metric\n",
        "def calculate_confidence_interval(scores):\n",
        "    lower_bound = np.percentile(scores, 2.5)\n",
        "    upper_bound = np.percentile(scores, 97.5)\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "# Calculate and print 95% confidence intervals\n",
        "accuracy_ci = calculate_confidence_interval(accuracy_scores)\n",
        "precision_ci = calculate_confidence_interval(precision_scores)\n",
        "recall_ci = calculate_confidence_interval(recall_scores)\n",
        "f1_ci = calculate_confidence_interval(f1_scores)\n",
        "roc_auc_ci = calculate_confidence_interval(roc_auc_scores)\n",
        "specificity_ci = calculate_confidence_interval(specificity_scores)\n",
        "\n",
        "print(f'Validation ROC AUC: 95% CI: [{roc_auc_ci[0]:.2f}, {roc_auc_ci[1]:.2f}]')\n",
        "print(f'Validation Accuracy:  95% CI: [{accuracy_ci[0]:.2f}, {accuracy_ci[1]:.2f}]')\n",
        "print(f'Validation Precision: 95% CI: [{precision_ci[0]:.2f}, {precision_ci[1]:.2f}]')\n",
        "print(f'Validation Recall: 95% CI: [{recall_ci[0]:.2f}, {recall_ci[1]:.2f}]')\n",
        "print(f'Validation F1-Score:  95% CI: [{f1_ci[0]:.2f}, {f1_ci[1]:.2f}]')\n",
        "print(f'Validation Specificity: 95% CI: [{specificity_ci[0]:.2f}, {specificity_ci[1]:.2f}]')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-l7gxojnU8g",
        "outputId": "d4ad8101-a244-4aac-eaae-e98f25aa65f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation ROC AUC: 95% CI: [0.50, 0.64]\n",
            "Validation Accuracy:  95% CI: [0.68, 0.77]\n",
            "Validation Precision: 95% CI: [0.49, 0.80]\n",
            "Validation Recall: 95% CI: [0.68, 0.77]\n",
            "Validation F1-Score:  95% CI: [0.68, 0.77]\n",
            "Validation Specificity: 95% CI: [0.00, 0.03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LASSO"
      ],
      "metadata": {
        "id": "MbjXhvAmXP17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = gene.drop(['Group'], axis=1)\n",
        "y = gene['Group']\n",
        "\n",
        "# Encode categorical target labels into numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Create Logistic Regression classifier with L1 regularization (Lasso)\n",
        "log_reg = LogisticRegression(penalty='l1', solver='liblinear', random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8CdDmaYXSSb",
        "outputId": "ccd68583-ae9a-4e66-c658-efb9a7827f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7455\n",
            "Precision: 0.8462\n",
            "Recall: 0.8049\n",
            "F1 Score: 0.8250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random Search"
      ],
      "metadata": {
        "id": "WTNgl7MSsnj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Define the parameter grid for Randomized Search\n",
        "param_dist = {\n",
        "    'C': np.logspace(-4, 4, 20),\n",
        "    'solver': ['liblinear'],\n",
        "    'max_iter': [1000, 5000, 10000, 20000],\n",
        "    'tol': [1e-4, 1e-3, 1e-2, 1e-1]\n",
        "}\n",
        "\n",
        "# Create Logistic Regression classifier with L1 regularization\n",
        "log_reg = LogisticRegression(penalty='l1', random_state=42)\n",
        "\n",
        "# Set up the Randomized Search with cross-validation\n",
        "random_search = RandomizedSearchCV(\n",
        "    log_reg, param_distributions=param_dist, n_iter=100,\n",
        "    scoring='roc_auc', cv=5, verbose=1, random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the Randomized Search model\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "# Predict on the test set with the best model\n",
        "y_pred = random_search.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n"
      ],
      "metadata": {
        "id": "GvZyktApAjoJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37252285-5719-4f39-babe-c285ff1c9a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "Best Parameters: {'tol': 0.001, 'solver': 'liblinear', 'max_iter': 20000, 'C': 0.615848211066026}\n",
            "Accuracy: 0.7636\n",
            "Precision: 0.7821\n",
            "Recall: 0.7636\n",
            "F1 Score: 0.7706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bayesian Optimization"
      ],
      "metadata": {
        "id": "TPh2pYg5s5-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Search best parameters\n",
        "random_search_params = {'tol': 0.001, 'solver': 'liblinear', 'max_iter': 20000, 'C':0.615848211066026}\n",
        "\n",
        "def objective(trial):\n",
        "    C = trial.suggest_float('C', 1e-4, 1e3, log=True)\n",
        "    max_iter = trial.suggest_int('max_iter', 1000, 100000)\n",
        "    tol = trial.suggest_float('tol', 1e-4, 1e-2, log=True)\n",
        "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
        "    clf = LogisticRegression(\n",
        "        penalty='l1', C=C, max_iter=max_iter, tol=tol, solver=solver, random_state=42\n",
        "    )\n",
        "    score = cross_val_score(clf, X_train_balanced, y_train_balanced, cv=5, scoring='roc_auc').mean()\n",
        "    return score\n",
        "\n",
        "# Create the study\n",
        "study = optuna.create_study(direction='maximize')\n",
        "\n",
        "# Define the initial random search trial\n",
        "def random_search_trial(trial):\n",
        "    trial.suggest_float('C', 206.913808111479, 206.913808111479, log=True)\n",
        "    trial.suggest_int('max_iter', 5000, 5000)\n",
        "    trial.suggest_float('tol', 0.0001, 0.0001, log=True)\n",
        "    trial.suggest_categorical('solver', ['liblinear'])\n",
        "\n",
        "# Start the optimization\n",
        "study.enqueue_trial(random_search_params)\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Print the best parameters and best AUC-ROC score from Optuna\n",
        "print(\"Best Parameters from Optuna:\", study.best_params)\n",
        "print(\"Best AUC-ROC Score from Optuna:\", study.best_value)\n",
        "\n",
        "# Retrieve the best parameters and train the model on the balanced data\n",
        "best_params = study.best_params\n",
        "clf = LogisticRegression(\n",
        "    penalty='l1', **best_params, random_state=42\n",
        ")\n",
        "clf.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_prob = clf.predict_proba(X_test)[:, 1]\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Test AUC-ROC: {roc_auc:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test Precision: {precision:.4f}\")\n",
        "print(f\"Test Recall: {recall:.4f}\")\n",
        "print(f\"Test F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "AVQprxjwbNJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbc01256-3083-47be-87ab-fac860a1448a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-08 12:32:56,592] A new study created in memory with name: no-name-43f52307-6433-4507-9ae4-235b71c7a790\n",
            "[I 2025-01-08 12:32:56,694] Trial 0 finished with value: 0.9185733333333334 and parameters: {'C': 0.615848211066026, 'max_iter': 20000, 'tol': 0.001, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9185733333333334.\n",
            "[I 2025-01-08 12:32:56,796] Trial 1 finished with value: 0.91924 and parameters: {'C': 0.2591818985497918, 'max_iter': 29167, 'tol': 0.004319761784026923, 'solver': 'saga'}. Best is trial 1 with value: 0.91924.\n",
            "[I 2025-01-08 12:32:57,334] Trial 2 finished with value: 0.9209733333333332 and parameters: {'C': 83.10784503953826, 'max_iter': 83268, 'tol': 0.00023864888482187419, 'solver': 'saga'}. Best is trial 2 with value: 0.9209733333333332.\n",
            "[I 2025-01-08 12:32:57,486] Trial 3 finished with value: 0.9205066666666667 and parameters: {'C': 7.834541398759501, 'max_iter': 45993, 'tol': 0.0001545862564113279, 'solver': 'liblinear'}. Best is trial 2 with value: 0.9209733333333332.\n",
            "[I 2025-01-08 12:32:57,649] Trial 4 finished with value: 0.9166266666666667 and parameters: {'C': 0.18449072736666638, 'max_iter': 72948, 'tol': 0.0008124866499254077, 'solver': 'saga'}. Best is trial 2 with value: 0.9209733333333332.\n",
            "[I 2025-01-08 12:32:57,755] Trial 5 finished with value: 0.5 and parameters: {'C': 0.00022821222878940804, 'max_iter': 26533, 'tol': 0.005979021790090433, 'solver': 'saga'}. Best is trial 2 with value: 0.9209733333333332.\n",
            "[I 2025-01-08 12:32:57,846] Trial 6 finished with value: 0.92024 and parameters: {'C': 20.59509174021478, 'max_iter': 83715, 'tol': 0.008023152237750894, 'solver': 'liblinear'}. Best is trial 2 with value: 0.9209733333333332.\n",
            "[I 2025-01-08 12:32:58,104] Trial 7 finished with value: 0.9230133333333332 and parameters: {'C': 14.168561523492006, 'max_iter': 82049, 'tol': 0.005948561254730024, 'solver': 'saga'}. Best is trial 7 with value: 0.9230133333333332.\n",
            "[I 2025-01-08 12:32:58,350] Trial 8 finished with value: 0.9220266666666666 and parameters: {'C': 50.9878302635726, 'max_iter': 12377, 'tol': 0.005995120108539974, 'solver': 'saga'}. Best is trial 7 with value: 0.9230133333333332.\n",
            "[I 2025-01-08 12:32:58,478] Trial 9 finished with value: 0.9203199999999999 and parameters: {'C': 192.04949468652373, 'max_iter': 82749, 'tol': 0.00039014825795315156, 'solver': 'liblinear'}. Best is trial 7 with value: 0.9230133333333332.\n",
            "[I 2025-01-08 12:32:58,668] Trial 10 finished with value: 0.5 and parameters: {'C': 0.0028149577740158712, 'max_iter': 54892, 'tol': 0.00231952044191471, 'solver': 'saga'}. Best is trial 7 with value: 0.9230133333333332.\n",
            "[I 2025-01-08 12:32:59,054] Trial 11 finished with value: 0.92344 and parameters: {'C': 483.92044962434744, 'max_iter': 1252, 'tol': 0.002531653142039242, 'solver': 'saga'}. Best is trial 11 with value: 0.92344.\n",
            "[I 2025-01-08 12:32:59,421] Trial 12 finished with value: 0.92344 and parameters: {'C': 995.5388575012719, 'max_iter': 99949, 'tol': 0.002372226584027256, 'solver': 'saga'}. Best is trial 11 with value: 0.92344.\n",
            "[I 2025-01-08 12:32:59,678] Trial 13 finished with value: 0.92344 and parameters: {'C': 904.0363370512148, 'max_iter': 4383, 'tol': 0.0026052202937141573, 'solver': 'saga'}. Best is trial 11 with value: 0.92344.\n",
            "[I 2025-01-08 12:32:59,986] Trial 14 finished with value: 0.9231333333333334 and parameters: {'C': 965.2497009086867, 'max_iter': 99724, 'tol': 0.001956957836975049, 'solver': 'saga'}. Best is trial 11 with value: 0.92344.\n",
            "[I 2025-01-08 12:33:00,156] Trial 15 finished with value: 0.9192266666666666 and parameters: {'C': 1.70295972602447, 'max_iter': 49563, 'tol': 0.0014976495352586263, 'solver': 'saga'}. Best is trial 11 with value: 0.92344.\n",
            "[I 2025-01-08 12:33:00,312] Trial 16 finished with value: 0.5 and parameters: {'C': 0.05769688828063206, 'max_iter': 63393, 'tol': 0.0004994832947983694, 'solver': 'saga'}. Best is trial 11 with value: 0.92344.\n",
            "[I 2025-01-08 12:33:00,675] Trial 17 finished with value: 0.9237466666666666 and parameters: {'C': 216.9926744768634, 'max_iter': 34452, 'tol': 0.003917941596924401, 'solver': 'saga'}. Best is trial 17 with value: 0.9237466666666666.\n",
            "[I 2025-01-08 12:33:00,810] Trial 18 finished with value: 0.5 and parameters: {'C': 0.01629188391253604, 'max_iter': 38672, 'tol': 0.00395307567545385, 'solver': 'liblinear'}. Best is trial 17 with value: 0.9237466666666666.\n",
            "[I 2025-01-08 12:33:01,078] Trial 19 finished with value: 0.9196399999999999 and parameters: {'C': 3.122557429655527, 'max_iter': 4420, 'tol': 0.0015015099240385107, 'solver': 'saga'}. Best is trial 17 with value: 0.9237466666666666.\n",
            "[I 2025-01-08 12:33:01,359] Trial 20 finished with value: 0.9246399999999999 and parameters: {'C': 190.87285277863643, 'max_iter': 33719, 'tol': 0.009596604609187667, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:01,651] Trial 21 finished with value: 0.9233333333333332 and parameters: {'C': 181.89236722604772, 'max_iter': 33892, 'tol': 0.008876601709843033, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:02,025] Trial 22 finished with value: 0.9234266666666666 and parameters: {'C': 174.47146023260188, 'max_iter': 14948, 'tol': 0.003763638610358472, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:02,335] Trial 23 finished with value: 0.9234 and parameters: {'C': 41.94033744367569, 'max_iter': 40488, 'tol': 0.003612661743141477, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:02,475] Trial 24 finished with value: 0.9233333333333332 and parameters: {'C': 241.29266935814834, 'max_iter': 23558, 'tol': 0.00901512980446252, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:02,586] Trial 25 finished with value: 0.92336 and parameters: {'C': 364.56245422970113, 'max_iter': 12952, 'tol': 0.00510782064876667, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:02,646] Trial 26 finished with value: 0.9197333333333335 and parameters: {'C': 4.589683905164276, 'max_iter': 61668, 'tol': 0.003051553993815444, 'solver': 'liblinear'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:02,785] Trial 27 finished with value: 0.9231199999999999 and parameters: {'C': 33.2589814913269, 'max_iter': 36166, 'tol': 0.0014038210479496028, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:02,850] Trial 28 finished with value: 0.9204800000000001 and parameters: {'C': 1.5037468655906514, 'max_iter': 57078, 'tol': 0.009493171983925927, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:02,916] Trial 29 finished with value: 0.9212933333333334 and parameters: {'C': 84.82707886427141, 'max_iter': 20694, 'tol': 0.0008445439992282193, 'solver': 'liblinear'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:03,065] Trial 30 finished with value: 0.9224533333333333 and parameters: {'C': 12.124436772740127, 'max_iter': 1834, 'tol': 0.001112464378597156, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:03,192] Trial 31 finished with value: 0.9231333333333334 and parameters: {'C': 501.74967082157536, 'max_iter': 43834, 'tol': 0.001992966898268482, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:03,310] Trial 32 finished with value: 0.92344 and parameters: {'C': 398.93403691431183, 'max_iter': 28855, 'tol': 0.0029847184153153124, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:03,415] Trial 33 finished with value: 0.9240266666666667 and parameters: {'C': 140.98761948589646, 'max_iter': 72881, 'tol': 0.004940454401309466, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:03,507] Trial 34 finished with value: 0.9230133333333332 and parameters: {'C': 76.05848433928215, 'max_iter': 70551, 'tol': 0.006905310940082845, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:03,609] Trial 35 finished with value: 0.9243599999999998 and parameters: {'C': 122.50783969701793, 'max_iter': 32556, 'tol': 0.004670857041861, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:03,706] Trial 36 finished with value: 0.9203733333333333 and parameters: {'C': 7.708958643220486, 'max_iter': 32510, 'tol': 0.0047875341453244335, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:03,776] Trial 37 finished with value: 0.9192533333333334 and parameters: {'C': 0.5136020297657382, 'max_iter': 48053, 'tol': 0.0001321009964502876, 'solver': 'liblinear'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:03,871] Trial 38 finished with value: 0.9220266666666666 and parameters: {'C': 114.18056040482993, 'max_iter': 42996, 'tol': 0.0071874181879255225, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:03,971] Trial 39 finished with value: 0.92304 and parameters: {'C': 24.54511412914692, 'max_iter': 27314, 'tol': 0.0048686823338707445, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:04,050] Trial 40 finished with value: 0.5 and parameters: {'C': 0.00043984133745484364, 'max_iter': 89104, 'tol': 0.006260932994911634, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:04,163] Trial 41 finished with value: 0.9234266666666666 and parameters: {'C': 69.55808011870081, 'max_iter': 18157, 'tol': 0.0033742940115911173, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:04,268] Trial 42 finished with value: 0.92404 and parameters: {'C': 425.613907726298, 'max_iter': 72495, 'tol': 0.0045524436561962065, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:04,376] Trial 43 finished with value: 0.9243599999999998 and parameters: {'C': 135.7779620093815, 'max_iter': 73857, 'tol': 0.004706922366036589, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:04,476] Trial 44 finished with value: 0.9226933333333334 and parameters: {'C': 31.24740964297397, 'max_iter': 74222, 'tol': 0.0054017773104271275, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:04,705] Trial 45 finished with value: 0.9209733333333332 and parameters: {'C': 116.65257485073515, 'max_iter': 75192, 'tol': 0.0002153785703605362, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:04,777] Trial 46 finished with value: 0.9043599999999999 and parameters: {'C': 0.15933936674064308, 'max_iter': 66007, 'tol': 0.007877031214592453, 'solver': 'liblinear'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:04,889] Trial 47 finished with value: 0.9243333333333335 and parameters: {'C': 15.022055411541746, 'max_iter': 89597, 'tol': 0.004456565328650198, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:05,062] Trial 48 finished with value: 0.9218 and parameters: {'C': 12.791109312309223, 'max_iter': 91396, 'tol': 0.0005559084273164209, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n",
            "[I 2025-01-08 12:33:05,153] Trial 49 finished with value: 0.9243066666666666 and parameters: {'C': 560.9672068864958, 'max_iter': 88326, 'tol': 0.009835086003044244, 'solver': 'saga'}. Best is trial 20 with value: 0.9246399999999999.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters from Optuna: {'C': 190.87285277863643, 'max_iter': 33719, 'tol': 0.009596604609187667, 'solver': 'saga'}\n",
            "Best AUC-ROC Score from Optuna: 0.9246399999999999\n",
            "Test AUC-ROC: 0.7474\n",
            "Test Accuracy: 0.7091\n",
            "Test Precision: 0.7535\n",
            "Test Recall: 0.7091\n",
            "Test F1 Score: 0.7233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIXT8hCDr8GW",
        "outputId": "cf979555-0ebe-4a36-d80d-8910b9450867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores:\n",
            "[0.8        0.81632653 0.85714286 0.81632653 0.87755102]\n",
            "Mean CV accuracy: 0.8335\n",
            "Test ROC AUC: 0.75\n",
            "Test Accuracy: 0.71\n",
            "Test Precision: 0.75\n",
            "Test Recall: 0.71\n",
            "Test F1-Score: 0.72\n",
            "Test Specificity: 0.64\n"
          ]
        }
      ],
      "source": [
        "selected_features_lasso = X_train.columns.tolist()\n",
        "\n",
        "# Best parameters from Bayesian Optimization with Optuna\n",
        "best_params_lasso = {\n",
        "    'C': 190.87285277863643,\n",
        "    'max_iter': 33719,\n",
        "    'solver': 'saga',\n",
        "    'tol':0.009596604609187667\n",
        "}\n",
        "\n",
        "# Train the Logistic Regression model again using only the selected features\n",
        "final_model_lasso = LogisticRegression(penalty='l1', **best_params_lasso, random_state=42)\n",
        "\n",
        "# Perform cross-validation with 5 folds\n",
        "cv_scores = cross_val_score(final_model_lasso, X_train[selected_features_lasso], y_train, cv=5, scoring='roc_auc')\n",
        "print(\"Cross-validation scores:\")\n",
        "print(cv_scores)\n",
        "print(f\"Mean CV accuracy: {np.mean(cv_scores):.4f}\")\n",
        "\n",
        "final_model_lasso.fit(X_train[selected_features_lasso], y_train)\n",
        "\n",
        "# Make predictions on the test set (predicted probabilities)\n",
        "y_pred_proba_lasso = final_model_lasso.predict_proba(X_test[selected_features_lasso])[:, 1]\n",
        "\n",
        "# Convert probabilities to predicted class labels\n",
        "y_pred_lasso = final_model_lasso.predict(X_test[selected_features_lasso])\n",
        "\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_lasso)\n",
        "precision = precision_score(y_test, y_pred_lasso, average = 'weighted')\n",
        "recall = recall_score(y_test, y_pred_lasso, average = 'weighted')\n",
        "f1 = f1_score(y_test, y_pred_lasso, average = 'weighted')\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba_lasso)\n",
        "\n",
        "# Calculate confusion matrix and extract TN, FP, FN, TP\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_lasso).ravel()\n",
        "\n",
        "# Calculate specificity\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "print(f'Test ROC AUC: {roc_auc:.2f}')\n",
        "print(f'Test Accuracy: {accuracy:.2f}')\n",
        "print(f'Test Precision: {precision:.2f}')\n",
        "print(f'Test Recall: {recall:.2f}')\n",
        "print(f'Test F1-Score: {f1:.2f}')\n",
        "print(f'Test Specificity: {specificity:.2f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LASSO Validation"
      ],
      "metadata": {
        "id": "YfBzHzBrtjCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation set\n",
        "X_val_ibd_lasso = gene_ibd.drop('Group', axis=1)\n",
        "y_val_ibd_lasso = gene_ibd['Group']\n",
        "\n",
        "# Encode categorical target labels into numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y_val_ibd_lasso)\n",
        "\n",
        "# Identify the features that are missing in the validation set\n",
        "missing_features = [feature for feature in selected_features_lasso if feature not in X_val_ibd_lasso.columns]\n",
        "\n",
        "# Add the missing features to the validation set with zero values using pd.concat\n",
        "missing_df_lasso = pd.DataFrame(0, index=X_val_ibd_lasso.index, columns=missing_features)\n",
        "X_val_ibd_lasso = pd.concat([X_val_ibd_lasso, missing_df_lasso], axis=1)\n",
        "\n",
        "# Ensure the columns are in the same order as the training features\n",
        "X_val_ibd_lasso = X_val_ibd_lasso[selected_features_lasso]\n",
        "\n",
        "#Make predictions on the validation set\n",
        "y_pred_prob_lasso_ibd= final_model_lasso.predict_proba(X_val_ibd_lasso)[:, 1]\n",
        "y_pred_lasso_ibd = final_model_lasso.predict(X_val_ibd_lasso)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_val = accuracy_score(y_encoded, y_pred_lasso_ibd)\n",
        "precision_val = precision_score(y_encoded, y_pred_lasso_ibd)\n",
        "recall_val = recall_score(y_encoded, y_pred_lasso_ibd, average=\"weighted\")\n",
        "f1_val = f1_score(y_encoded, y_pred_lasso_ibd,  average=\"weighted\")\n",
        "roc_auc_val = roc_auc_score(y_encoded, y_pred_prob_lasso_ibd)\n",
        "\n",
        "# Calculate specificity\n",
        "tn_val, fp_val, fn_val, tp_val = confusion_matrix(y_encoded, y_pred_lasso_ibd).ravel()\n",
        "specificity_val = tn_val / (tn_val + fp_val)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f'Validation ROC AUC: {roc_auc_val:.2f}')\n",
        "print(f'Validation Accuracy: {accuracy_val:.2f}')\n",
        "print(f'Validation Precision: {precision_val:.2f}')\n",
        "print(f'Validation Recall: {recall_val:.2f}')\n",
        "print(f'Validation F1-Score: {f1_val:.2f}')\n",
        "print(f'Validation Specificity: {specificity_val:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcLwBdU1buyG",
        "outputId": "c02a32fb-05ae-4b51-be57-bb14e872d850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation ROC AUC: 0.53\n",
            "Validation Accuracy: 0.70\n",
            "Validation Precision: 0.74\n",
            "Validation Recall: 0.70\n",
            "Validation F1-Score: 0.70\n",
            "Validation Specificity: 0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##95% CI"
      ],
      "metadata": {
        "id": "q9jDTSSBkCNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap_ci(metric_func, y_true, y_pred, y_proba=None, n_bootstraps=1000, alpha=0.95):\n",
        "    bootstrapped_scores = []\n",
        "    n_size = len(y_true)\n",
        "\n",
        "    for i in range(n_bootstraps):\n",
        "        indices = resample(range(n_size), replace=True, n_samples=n_size, random_state=i)\n",
        "        y_true_resampled = y_true[indices]\n",
        "        y_pred_resampled = y_pred[indices]\n",
        "\n",
        "        if y_proba is not None:\n",
        "            y_proba_resampled = y_proba[indices]\n",
        "            score = metric_func(y_true_resampled, y_proba_resampled)\n",
        "        else:\n",
        "            score = metric_func(y_true_resampled, y_pred_resampled)\n",
        "\n",
        "        bootstrapped_scores.append(score)\n",
        "\n",
        "    # Compute the confidence interval\n",
        "    sorted_scores = np.sort(bootstrapped_scores)\n",
        "    lower_bound = np.percentile(sorted_scores, (1 - alpha) / 2 * 100)\n",
        "    upper_bound = np.percentile(sorted_scores, (1 + alpha) / 2 * 100)\n",
        "\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "# Apply bootstrap CI for each metric\n",
        "accuracy_ci = bootstrap_ci(accuracy_score, y_test_lasso, y_pred_lasso)\n",
        "precision_ci = bootstrap_ci(precision_score, y_test_lasso, y_pred_lasso)\n",
        "recall_ci = bootstrap_ci(recall_score, y_test_lasso, y_pred_lasso)\n",
        "f1_ci = bootstrap_ci(f1_score, y_test_lasso, y_pred_lasso)\n",
        "roc_auc_ci = bootstrap_ci(roc_auc_score, y_test_lasso, y_pred_lasso, y_proba=y_pred_proba_lasso)\n",
        "\n",
        "# Specificity calculation\n",
        "def specificity_metric(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "specificity_ci = bootstrap_ci(specificity_metric, y_test_lasso, y_pred_lasso)\n",
        "\n",
        "# Print evaluation metrics with their 95% Confidence Intervals\n",
        "print(f'Test ROC AUC: {roc_auc:.2f} (95% CI: {roc_auc_ci[0]:.2f}, {roc_auc_ci[1]:.2f})')\n",
        "print(f'Test Accuracy: {accuracy:.2f} (95% CI: {accuracy_ci[0]:.2f}, {accuracy_ci[1]:.2f})')\n",
        "print(f'Test Precision: {precision:.2f} (95% CI: {precision_ci[0]:.2f}, {precision_ci[1]:.2f})')\n",
        "print(f'Test Recall: {recall:.2f} (95% CI: {recall_ci[0]:.2f}, {recall_ci[1]:.2f})')\n",
        "print(f'Test F1-Score: {f1:.2f} (95% CI: {f1_ci[0]:.2f}, {f1_ci[1]:.2f})')\n",
        "print(f'Test Specificity: {specificity:.2f} (95% CI: {specificity_ci[0]:.2f}, {specificity_ci[1]:.2f})')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMnUpMWpccxl",
        "outputId": "3d48e800-ab4e-4d7d-cca9-8d893db1d561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation ROC AUC: (95% CI: 0.46, 0.59)\n",
            "Validation Specificity:(95% CI: 0.07, 0.19)\n",
            "Validation Accuracy: (95% CI: 0.69, 0.78)\n",
            "Validation Precision:  (95% CI: 0.79, 0.83)\n",
            "Validation Recall: (95% CI: 0.69, 0.78)\n",
            "Validation F1-Score:  (95% CI: 0.57, 0.69)\n"
          ]
        }
      ]
    }
  ]
}